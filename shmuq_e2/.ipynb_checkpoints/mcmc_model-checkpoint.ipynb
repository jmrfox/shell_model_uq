{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "# MCMC evaluation of E2 effective charge distributions\n",
    "# Fox 2022\n",
    "#\n",
    "# more general version of the MCMC scripts with version numbers\n",
    "# can set which variables to model in argument\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'family' : 'serif',\n",
    "        'serif'  : ['Palatino'],\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('text', usetex=True)\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import emcee\n",
    "from multiprocessing import Pool\n",
    "from scipy.optimize import minimize, minimize_scalar\n",
    "\n",
    "    \n",
    "def optimal_n_bins(y,max_bins=100):\n",
    "    from scipy.stats import iqr\n",
    "    n_bins = int((max(y) - min(y))/(2*iqr(y)*len(y)**(-1/3)))\n",
    "    return min(n_bins,max_bins)\n",
    "\n",
    "def Bweisskopf(l,A):\n",
    "    # Weisskopf (single-particle) estimate in e^2 fm^2l\n",
    "    return (1/(4*np.pi)) * (3/(3+l))**2 * (1.2*A**(1/3))**(2*l)\n",
    "\n",
    "# define prior parameter values\n",
    "e_p_brown, e_n_brown = 1.36, 0.45\n",
    "mu_blomqvist, beta_blomqvist = 0.9, 0.7 \n",
    "\n",
    "prior_params = [e_p_brown,e_n_brown,mu_blomqvist,beta_blomqvist]\n",
    "\n",
    "def Bth_model_Wu(parameters,Mth_p_vec,Mth_n_vec,A_vec):\n",
    "    e_p, e_n, mu, beta = parameters\n",
    "    b_sqr_vec = mu*A_vec**(1/3) + beta\n",
    "    Bth_vec = b_sqr_vec**2 * ( e_p * np.array(Mth_p_vec) + e_n * np.array(Mth_n_vec))**2\n",
    "    single_particle_estimates = Bweisskopf(2,A_vec)\n",
    "    return Bth_vec / single_particle_estimates\n",
    "\n",
    "print('Loading data...')\n",
    "fn_data_for_model = 'e2_data_for_model_201021.pkl'\n",
    "with open(fn_data_for_model,'rb') as fh:\n",
    "    [nuc_dict_list, Mth_p_usdb_list,Mth_n_usdb_list,Mth_p_vec_list,Mth_n_vec_list,title_string_list, Bexp_e2fm4_list, Bexp_unc_e2fm4_list, Bexp_Wu_list, Bexp_unc_Wu_list] = pkl.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_err_threshold = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to grab first element of each df row\n",
    "Bexp_Wu_list = [x.iloc[0] for x in Bexp_Wu_list]\n",
    "Bexp_unc_Wu_list = [x.iloc[0] for x in Bexp_unc_Wu_list]\n",
    "A_vec = np.array([nuc_dict['A'] for nuc_dict in nuc_dict_list])\n",
    "Bexp_Wu_vec = np.array(Bexp_Wu_list)\n",
    "Bexp_unc_Wu_vec = np.array(Bexp_unc_Wu_list)\n",
    "Mth_p_usdb_vec = np.array(Mth_p_usdb_list)\n",
    "Mth_n_usdb_vec = np.array(Mth_n_usdb_list)\n",
    "Mth_p_array = np.array(Mth_p_vec_list)\n",
    "Mth_n_array = np.array(Mth_n_vec_list)\n",
    "n_transitions, n_samples = Mth_p_array.shape\n",
    "\n",
    "# drop transitions with large relative error\n",
    "if relative_err_threshold is not None:\n",
    "    Bth_usdb_prior = Bth_model_Wu(prior_params, Mth_p_usdb_vec, Mth_n_usdb_vec,A_vec)\n",
    "    Berr_rel = (Bexp_Wu_vec - Bth_usdb_prior)/Bexp_Wu_vec\n",
    "    mask = np.abs(Berr_rel) < relative_err_threshold\n",
    "\n",
    "    A_vec = A_vec[mask]\n",
    "    Bexp_Wu_vec = Bexp_Wu_vec[mask]\n",
    "    Bexp_unc_Wu_vec = Bexp_unc_Wu_vec[mask]\n",
    "    Mth_p_usdb_vec = Mth_p_usdb_vec[mask]\n",
    "    Mth_n_usdb_vec = Mth_n_usdb_vec[mask]\n",
    "    Mth_p_array = Mth_p_array[mask]\n",
    "    Mth_n_array = Mth_n_array[mask]\n",
    "    n_transitions, n_samples = Mth_p_array.shape\n",
    "\n",
    "def chi_squared(parameters,sigmaB_apriori):\n",
    "    sqr_errors = (Bexp_Wu_vec - Bth_model_Wu(parameters,Mth_p_usdb_vec,Mth_n_usdb_vec,A_vec))**2\n",
    "    B_unc_sqr_vec = np.array( [(sigmaB_apriori**2 + sigmaB**2) for sigmaB in Bexp_unc_Wu_vec])\n",
    "    R_sqr =  sqr_errors / B_unc_sqr_vec\n",
    "    return  np.sum(R_sqr)\n",
    "\n",
    "def objective(sigmaB_apriori):\n",
    "    X2 = chi_squared(prior_params,sigmaB_apriori)\n",
    "    dof = n_transitions - 66\n",
    "    return (X2/dof - 1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding a priori B-value uncertainty...\n",
      "A priori B(E2) uncertainty = 5.231348847577559\n"
     ]
    }
   ],
   "source": [
    "print('Finding a priori B-value uncertainty...')\n",
    "opt_result = minimize_scalar(objective)\n",
    "sigmaB_apriori = opt_result.x\n",
    "print(f'A priori B(E2) uncertainty = {sigmaB_apriori}')\n",
    "sigma_B_sqr_vec = [(sigmaB_apriori**2 + sigmaB**2) for sigmaB in Bexp_unc_Wu_vec]\n",
    "\n",
    "B_unc_sqr_vec = np.array( [sigmaB_apriori**2 + sigmaB**2 for sigmaB in Bexp_unc_Wu_vec] )\n",
    "mu_std = 3\n",
    "beta_std = 3\n",
    "ep_bounds = (1.,2.)\n",
    "en_bounds = (0.,1.)\n",
    "\n",
    "def ep_log_prior(ep):\n",
    "    if ep>ep_bounds[0] and ep<ep_bounds[1]:\n",
    "        return 0.\n",
    "    else:\n",
    "        return -np.infty\n",
    "    \n",
    "def en_log_prior(en):\n",
    "    if en>en_bounds[0] and en<en_bounds[1]:\n",
    "        return 0.\n",
    "    else:\n",
    "        return -np.infty\n",
    "    \n",
    "def normal_pdf(x,m,s):\n",
    "    norm = (s * np.sqrt(2*np.pi))**-1\n",
    "    return norm * np.exp( - 0.5 * ((x-m)/s)**2)\n",
    "\n",
    "def log_normal_pdf(x,m,s):\n",
    "    norm = (s * np.sqrt(2*np.pi))**-1\n",
    "    return np.log(norm) - 0.5 * ((x-m)/s)**2\n",
    "\n",
    "def mu_log_prior(mu):\n",
    "    return log_normal_pdf(mu,mu_blomqvist,mu_std)\n",
    "    \n",
    "def beta_log_prior(beta):\n",
    "    return log_normal_pdf(beta,beta_blomqvist,beta_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = 'eff_charges'\n",
    "# variables = 'osc_length_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bexp_tiled = np.tile(Bexp_Wu_vec.reshape(n_transitions,1),n_samples)\n",
    "B_unc_sqr_tiled = np.tile(B_unc_sqr_vec.reshape(n_transitions,1),n_samples)\n",
    "single_particle_estimates = Bweisskopf(2,A_vec)\n",
    "spe_tiled = np.tile(single_particle_estimates.reshape(n_transitions,1),n_samples)\n",
    "\n",
    "if variables == 'eff_charges':\n",
    "    def log_prior(theta):\n",
    "        return ep_log_prior(theta[0]) + en_log_prior(theta[1])\n",
    "        \n",
    "    # redefine likelihood to be faster\n",
    "    b4_vec = (mu_blomqvist*A_vec**(1/3) + beta_blomqvist)**2\n",
    "    b4_tiled = np.tile(b4_vec.reshape(n_transitions,1),n_samples)\n",
    "    def log_posterior(theta):\n",
    "        # sum over data, average over samples\n",
    "        sqr_error_tiled = ( Bexp_tiled - (b4_tiled/spe_tiled)*(theta[0]*Mth_p_array + theta[1]*Mth_n_array)**2 )**2\n",
    "        log_likelihood =  - 0.5 * np.sum(sqr_error_tiled / B_unc_sqr_tiled) / n_samples\n",
    "        return log_prior(theta) + log_likelihood\n",
    "    \n",
    "    def starting_point():\n",
    "        ep = np.random.rand() + 1\n",
    "        en = np.random.rand()\n",
    "        return [ep,en]\n",
    "    \n",
    "elif variables == 'osc_length_params':\n",
    "    def log_prior(theta):\n",
    "        return mu_log_prior(theta[0]) + beta_log_prior(theta[1])\n",
    "    \n",
    "    Bth_array = (e_p_brown*Mth_p_array + e_n_brown*Mth_n_array)**2\n",
    "    \n",
    "    def log_posterior(theta):\n",
    "        # sum over data, average over samples\n",
    "        b4_vec = (theta[0]*A_vec**(1/3) + theta[1])**2\n",
    "        b4_tiled = np.tile(b4_vec.reshape(n_transitions,1),n_samples)\n",
    "        sqr_error_tiled = ( Bexp_tiled - (b4_tiled/spe_tiled)*Bth_array )**2\n",
    "        log_likelihood =  - 0.5 * np.sum(sqr_error_tiled / B_unc_sqr_tiled) / n_samples\n",
    "        return log_prior(theta) + log_likelihood\n",
    "    \n",
    "    def starting_point():\n",
    "        [mu,beta] = [-1.,-1.]\n",
    "        while mu<0. and beta<0.:\n",
    "            mu = mu_std*np.random.normal() + mu_blomqvist\n",
    "            beta = beta_std*np.random.normal() + beta_blomqvist\n",
    "        return [mu,beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/workspace/fox39/anaconda3/envs/uq/lib/python3.7/site-packages/scipy/optimize/_numdiff.py:557: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "/usr/workspace/fox39/anaconda3/envs/uq/lib/python3.7/site-packages/scipy/optimize/_numdiff.py:557: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: 46.85036995984206\n",
       " hess_inv: array([[ 0.01740735, -0.01617084],\n",
       "       [-0.01617084,  0.01687882]])\n",
       "      jac: array([ 0.00000000e+00, -2.38418579e-06])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 45\n",
       "      nit: 8\n",
       "     njev: 13\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([1.5078016 , 0.33469808])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(theta):\n",
    "    return -log_posterior(theta)\n",
    "\n",
    "opt = minimize(objective,x0=[1.5,0.5])\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_walkers = 32\n",
    "n_steps = 16000\n",
    "n_params = 2\n",
    "use_pool = True\n",
    "\n",
    "q0 = [starting_point() for _ in range(n_walkers)]\n",
    "\n",
    "print('Beginning MCMC...')\n",
    "print(f'N walkers: {n_walkers}')\n",
    "print(f'N steps: {n_steps}')\n",
    "\n",
    "if args.relative_err_threshold is None:\n",
    "    nametag = f'{variables}'\n",
    "else:\n",
    "    nametag = f'{variables}_RET{relative_err_threshold}'\n",
    "    \n",
    "ckpt_filename = f'checkpoint_{nametag}.h5'\n",
    "backend = emcee.backends.HDFBackend(ckpt_filename)\n",
    "backend.reset(n_walkers, n_params)\n",
    "\n",
    "if use_pool:\n",
    "    with Pool() as pool:\n",
    "        sampler = emcee.EnsembleSampler(n_walkers, n_params, log_posterior, pool=pool, backend=backend)\n",
    "        start = time()\n",
    "        sampler.run_mcmc(q0, n_steps, progress=True,);\n",
    "        end = time()\n",
    "        multi_time = end - start\n",
    "        print(\"Multiprocessing took {0:.1f} seconds\".format(multi_time))\n",
    "else:\n",
    "    sampler = emcee.EnsembleSampler(n_walkers, n_params, log_posterior)\n",
    "    t1 = time()\n",
    "    sampler.run_mcmc(q0, n_steps, progress=True,);\n",
    "    t2 = time()\n",
    "    print(\"Processing took {0:.1f} seconds\".format(t2-t1))\n",
    "\n",
    "\n",
    "with open(f'traces_{nametag}.pkl','wb') as fh:\n",
    "    pkl.dump(sampler.chain,fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uq",
   "language": "python",
   "name": "uq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
